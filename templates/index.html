<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Multimodal Chatbot with TF.js Gestures & Face</title>
  <!-- Bootstrap 5 CSS -->
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">

  <style>
    body { background: #f2f2f2; font-family: "Segoe UI", Tahoma, Geneva, Verdana, sans-serif; }
    .chat-container { max-width: 800px; margin: 20px auto; }
    #chat-box {
      background: #fff; border: 1px solid #ddd; border-radius: 10px;
      padding: 20px; height: 400px; overflow-y: auto; margin-bottom: 20px;
    }
    .chat-message { margin-bottom: 15px; }
    .user-message { text-align: right; }
    .bot-message  { text-align: left; }
    .bubble {
      display: inline-block; padding: 10px 15px; border-radius: 20px;
      max-width: 70%; word-wrap: break-word;
    }
    .user-message .bubble { background: #0d6efd; color: #fff; }
    .bot-message  .bubble { background: #e9ecef; color: #333; }
    video#camera { border:1px solid #ccc; border-radius: 10px; }
  </style>
</head>
<body>

  <nav class="navbar navbar-light bg-light shadow-sm">
    <div class="container">
      <span class="navbar-brand">Multimodal Chatbot + TF.js Gestures</span>
    </div>
  </nav>

  <div class="container chat-container">
    <!-- Live camera feed for gesture & face detection -->
    <div class="mb-3 text-center">
      <video id="camera" width="320" height="240" autoplay muted playsinline></video>
    </div>

    <div id="chat-box"></div>

    <!-- Chat Form -->
    <form id="chat-form" class="card p-4 shadow-sm mb-3" enctype="multipart/form-data">
      <div class="mb-3">
        <label class="form-label">Message:</label>
        <textarea id="text" name="text" class="form-control" rows="2"></textarea>
      </div>
      <!-- other inputs omitted for brevityâ€¦ -->
      <button class="btn btn-primary">Send</button>
    </form>
  </div>

  <!-- jQuery -->
  <script src="https://code.jquery.com/jquery-3.6.0.min.js"></script>
  <!-- TensorFlow.js Core -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.7.0/dist/tf.min.js"></script>
  <!-- Handpose Model -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/handpose@0.0.7/dist/handpose.min.js"></script>
  <!-- Face Landmarks Detection Model -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/face-landmarks-detection@1.1.5/dist/face-landmarks-detection.min.js"></script>

  <script>
  // Utility: append a gesture/face event as a user message and send to backend
  let lastGesture = null, lastFace = false;
  function appendUserGesture(gesture) {
    $("#chat-box").append(
      `<div class='chat-message user-message'><div class='bubble'><em>[${gesture}]</em></div></div>`
    );
    // scroll
    $("#chat-box").scrollTop($("#chat-box")[0].scrollHeight);
    // send to /chat as text
    const fd = new FormData();
    fd.append("text", `[${gesture}]`);
    fd.append("output_type", "text");
    $.ajax({
      type: "POST",
      url: "/chat",
      data: fd,
      contentType: false,
      processData: false,
      success(data) {
        renderBot(data);
      }
    });
  }

  function renderBot(data) {
    let html = "";
    if (data.response) html += `<div><strong>Bot:</strong> ${data.response}</div>`;
    $("#chat-box").append(
      `<div class='chat-message bot-message'><div class='bubble'>${html}</div></div>`
    );
    $("#chat-box").scrollTop($("#chat-box")[0].scrollHeight);
  }

  // Setup camera
  async function setupCamera() {
    const video = document.getElementById("camera");
    const stream = await navigator.mediaDevices.getUserMedia({video:true});
    video.srcObject = stream;
    return new Promise((resolve) => {
      video.onloadedmetadata = () => resolve(video);
    });
  }

  // Load models & start detection loop
  async function main() {
    const video = await setupCamera();

    // Load Handpose
    const handModel = await handpose.load();
    // Load FaceMesh (MediaPipe FaceMesh package)
    const faceModel = await faceLandmarksDetection.load(
      faceLandmarksDetection.SupportedPackages.mediapipeFacemesh
    );

    async function detect() {
      // Hand detection
      const hands = await handModel.estimateHands(video, true);
      if (hands.length > 0) {
        const lm = hands[0].landmarks;
        // y coordinate: tip of thumb = lm[4][1], MCP = lm[2][1]
        const gesture = (lm[4][1] < lm[2][1]) ? "thumbs_up" : "thumbs_down";
        if (gesture !== lastGesture) {
          lastGesture = gesture;
          appendUserGesture(gesture);
        }
      } else {
        lastGesture = null;
      }

      // Face detection
      const faces = await faceModel.estimateFaces({input: video});
      const hasFace = faces.length > 0;
      if (hasFace && !lastFace) {
        lastFace = true;
        appendUserGesture("face_detected");
      } else if (!hasFace) {
        lastFace = false;
      }

      requestAnimationFrame(detect);
    }

    detect();
  }

  main();
  </script>
</body>
</html>
